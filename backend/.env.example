# InuaBreath Backend Environment Template
# Copy this file to .env and fill required values.

# Required: IO Intelligence API key
# Get from: https://intelligence.io.solutions
IOINTELLIGENCE_API_KEY=your_io_intelligence_api_key_here

# Optional: Opik tracing
# Get from: https://www.comet.com/opik/
OPIK_API_KEY=
OPIK_PROJECT_NAME=InuaBreath
OPIK_WORKSPACE=

# Model configuration
LLM_MODEL_NAME=meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
# Optional: separate model for crisis classifier fallback (defaults to INUA_MODEL_VERSION/LLM_MODEL_NAME)
CRISIS_MODEL_NAME=

# Prompt/model version tags (used in Opik metadata)
INUA_PROMPT_VERSION=v1
INUA_MODEL_VERSION=

# LLM request timeout (seconds)
LLM_TIMEOUT_SECONDS=20

# API server
PORT=8001

# CORS (comma-separated origins)
# Example: https://your-frontend.com,http://localhost:3000
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8081

# Optional API authentication for /api/agent/chat
API_AUTH_REQUIRED=false
API_AUTH_KEY=change_me_to_a_long_random_secret
